     
Transcript     
0:00     
hello hi Hi how are you I guess I'm okay     
0:09     
good I've decided to go 2D with my Integrity project for a bit okay because     
0:18     
uh I was looking at the math and it's an indeterminant     
0:25     
structure you mean the 3D version yes the 3D version yes     
0:31     
2D not not not or shouldn't be yeah usually the 2D math works out     
0:37     
better than the 3D math yeah and the triangles work better     
0:42     
than the hexagons oh of course yeah so so I've got um a triangle prism that     
0:50     
works and I'm going to get the 2D mat to work and I'm going to say well I need to     
0:56     
get the whole thing together but so far no     
1:02     
well good luck with that yeah yeah I have to introduce this to my professors     
1:08     
this afternoon okay good luck with that no no we want the whole thing it's     
1:15     
like you guys even know what you're talking     
1:21     
about anyway yeah so think it's in like I'm reading two sets of different     
1:28     
maths and one is on tensegrity and the other one is on the vertex model okay     
1:37     
yeah so I if I could somehow combine them I I could just write a thesis and be     
1:45     
done great I don't think it's that easy another word yeah I'll I'll find it for     
1:50     
you and send it send it to you sounds good yeah all right um so yeah what     
1:58     
don't we talk about Google summer of code so if you go to the neurostars page and I think a lot of people have already     
2:05     
uh gotten this information from incf but it looks like our project for this year is posted on uh their in cf's     
2:15     
uh discourse so they have this discourse uh they run called     
2:28     
neurostar.com of this stuff on um the projects for the year so this year's     
2:34     
projects are posted there are a lot of projects being sponsored by incf maybe about 20 or 30 well maybe about 20 and     
2:42     
uh we're project four so actually 4.1 so we have graph neural networks is     
2:50     
the title of the project uh sponsored by the openworm foundation as well as incf     
2:56     
so we'll be working the dorm projects are all through the open or foundation and it's just usually you know we have     
3:03     
to have an org that we sort of people interact with during the community period So Not only would you be     
3:10     
interacting with Diva Worm but the larger openworm group um so yeah the project is     
3:17     
basically the same as last year we're looking for people to develop graph     
3:22     
neural networks and graph neural network uh representations graph embeddings things     
3:28     
like that so we have during the project period we have sort of three steps that     
3:34     
you can follow uh so wait a minute uh so yeah we     
3:39     
have uh I think it was like two years ago jiong Lee who's actually sort of     
3:47     
took the initiative in the first year of this project to sort of Define the parameters of it he developed a pipeline     
3:55     
with three parts uh the first one is refining a means the segment Raw data     
4:00     
and Incorporated in the dorm pipeline which is basically image segmentation     
4:06     
and making sure the input data looks good uh so we've worked on that a lot uh     
4:12     
both in 2022 and then last year with honu shogul who was also in the project so you know     
4:21     
we're doing that we that's kind of been worked out already but you may you know may have     
4:27     
things to contribute there if you want the second part of the pipeline is ref finding our method for deriving     
4:34     
graphin beddings so you know a Haman worked on graphin Bings a little bit     
4:39     
last summer um and he worked on things that you know went from graphin Bings to     
4:45     
topological data analysis but you know the summer being what it is it's just that summer period     
4:53     
you know you didn't have time to really work it out all the way so between gong's work and     
5:00     
wataru kakar's work and hamu shogo's work that's basically the bulk of the     
5:08     
work that's been done on this and you'll find that in the uh GitHub repository so     
5:13     
there's a GitHub repository here dlearn Devo graph and and a lot of the work is     
5:19     
in there and then the third part of the pipeline is more tightly integrating     
5:25     
daph as a network structure Discovery module of dvo learn so this is where     
5:31     
we're looking for people who can take a a graph embedding create a graph     
5:36     
embedding and then turn that into other things that are useful to the dvo learn     
5:42     
platform so the dvo learn platform is a machine learning platform for segmenting images so in a sense some of that work     
5:50     
has already could be been contributed to step one but step three actually     
5:56     
involves you know maybe a more sort of graph oriented approach to Deva Deva     
6:03     
learn so you know taking the uh segmented image data and turning it into     
6:09     
graphs and then doing things with graph Theory and and network Theory now I     
6:15     
don't expect people to jump on three uh you know like in a very sophisticated     
6:21     
way but we can talk about how you might be able to contribute to three um and     
6:28     
you know I I we we do a lot of that in the group we talk about networks and we     
6:34     
have I have some references I think I put some references at the end I did not well we have some references that one     
6:40     
can uh consult to uh work on that H so     
6:46     
basically we're looking for people who are good at you know uh kind of working on their own working out their problem     
6:52     
on their own this is kind of a hard problem because grarl networks are uh     
6:58     
pretty hard to they're pretty opaque in a lot of ways they're not as uh you know not as easy     
7:05     
to understand as some of the basic machine learning techniques so it might be a little bit of a     
7:11     
challenge but you know that's something that you know and again you know you just take a piece of this and work on it     
7:17     
so the idea is that we're having this project that we've had the last two years and you take a piece of it and you     
7:24     
know or you can work on refining something that already exists and you can build a project around     
7:31     
that so uh what can you do before gck you can get involved in the open orm     
7:37     
Slack so we have a slack for openworm you know not don't just look at dorm look at all the channels look at all the     
7:43     
different things going on in the project we have uh all sorts of you know uh open     
7:50     
worm is built on secondary data we have a lot of movement data we have a lot of     
7:55     
other types of uh cellular level data and so this is something that we can you     
8:01     
know if you're interested in using other types of data we can do that but the focus is going to be on cgans     
8:07     
development for the summer we also have a website dorm. weebly.com this is our uh our group     
8:16     
website here we have here all sorts of things we have Publications under     
8:22     
academic output we have uh previous Goog Google summer code projects under     
8:27     
educations notebooks and media media we have a number of public lectures which     
8:33     
maybe will give you some background into some of the things we're thinking about and some of the work we've done on     
8:39     
networks we have all sorts of things here so uh definitely check that out as     
8:45     
well as the openworm foundation website uh we also have a GitHub so this     
8:53     
is the GitHub for Divo graph and so this is under in the dvo     
9:00     
learn organization so dvo learn is of course the main package that we're kind of working     
9:08     
towards building modules of Divo graph is sort of separate because we haven't worked it out it's not incorporated into     
9:15     
the main release but we're trying to work out in a lot of the details of this before we actually make a formal     
9:23     
release uh so yeah we have stage one here stage two here and we have some     
9:29     
other things you know this this uh repo will likely undergo a refactoring before     
9:36     
the beginning of uh Google summer code but you know we've been working on a lot     
9:42     
of things so you know we have the resources we just have to like put these     
9:48     
things together and uh you know really for the proposal you don't need to do a     
9:54     
lot of work you might make a couple of commits to this repo but I'm looking for people who can propose something that is     
10:01     
both interesting well three things interesting uh and you know     
10:08     
useful and uh sort of within the time scope of the project so you know you     
10:14     
only have this is a 350 Hour project as they say in the     
10:20     
application um that means that you know you only have a 350 hour window to do     
10:27     
this in so you know you have 20 hours a week every week in the summer uh and so     
10:33     
you you don't have infinite amount of time it's not like a year-long project so you have to propose something that's     
10:39     
within the scope of that but also interesting and useful and so that's     
10:44     
what we have uh in terms of yeah so the GitHub repo is here you you know you I would     
10:50     
suggest that people Fork it and look it over and ask questions about it uh we also have dvo learn which is     
10:57     
the organization that this is under so this is the main package that we work on     
11:03     
uh we have a number of releases of this uh we have a lot of different uh last     
11:09     
summer uh sush mon uh ready was working on a number of different modules things     
11:15     
like sellam which is the segment anything model and uh he was working on putting our models on hugging face so     
11:23     
the dvo learn modules are a nucleus segmentor a membrane segmentor and a     
11:29     
winning AG population model so all those are necessary for segmenting seelan     
11:34     
cells uh not only just kind of static images but Dynamic images across the     
11:40     
lineage tree which if you read a little bit about uh I think I have some things pinned to the uh slack Channel you'll be     
11:49     
able to read about basic celegans development and you'll know what some of these terms are so I suggest that you     
11:55     
read a what a bit about Sean's development to get uh sort of oriented to some of these     
12:02     
terms but these are three things that we use for basically we can plug that into     
12:08     
that step one in uh daph and then step two is turning these things into graph     
12:16     
embeddings and then or the segmented images into graph embeddings and then step three is doing other things with     
12:23     
gra those graph eddings and with networks that's where we are please uh     
12:28     
okay now for people interested in Google Su rope code I'm going to go over some of our community resources and some of     
12:34     
these are going to be things that you want to check out before you apply just to get a taste for what our community     
12:41     
does and what we're trying to accomplish so the first thing you want to do is join the uh openworm slack that's the     
12:47     
openworm foundation and there's a link in the description of the project on     
12:53     
neurostars so please join as when you can if you need an invite let me know     
12:59     
contact me and I can invite you to the slack the slack we do our weekly     
13:04     
meetings we record those put those on YouTube and I usually put those in the channel for people to check out after     
13:11     
the meeting is concluded so we often have people come synchronously to the meeting but people also check out our     
13:17     
meeting asynchronously as well and we do this weekly on a weekly basis we also have people you know     
13:24     
members of the channel who post things are interested in collaborating or they have In Articles or topics that they     
13:30     
want to discuss so it's really you know it's a good resource to be involved in     
13:36     
the community asynchronously especially we also have a channel dvo learn Devo graph and that's actually more focused     
13:44     
on machine learning and deep learning and so if you're interested in the graph     
13:50     
interal networks project you might want to join in in this Channel and check out some of the things that have been put in     
13:56     
the channel over the last couple years we have a number of graph learning     
14:02     
resources here we have a number of other types of image segmentation resources     
14:08     
and the like uh dvo learn and D graph and dorm are both public channels so     
14:14     
when you get into the slack just you know look for those channels and join or     
14:20     
let me know in the main dorm Channel and I can invite you the open roomm foundation also has other channels so     
14:26     
there are a lot of things going on in that community uh there's c302 which is a simulation     
14:32     
platform for uh celegans neurons we have uh a data Channel which is where we talk     
14:40     
about open data sets we have a community Channel we have a general Channel which is where most of the announcements are     
14:46     
also a science channel the way that the openworm GitHub works is that it sends     
14:52     
notifications of different issues that are being worked on to the channels so in the CH Science Channel you can see     
14:58     
that there was an issue that was closed by Hussein ather uh on February 22nd     
15:05     
there's another issue one number 114 create sample neuroml connectm output     
15:10     
that was uh that's being worked on this is by Steve Larson and so this is you     
15:16     
can keep it a breast of the different GitHub issues that are Salient to people in the community people are currently     
15:23     
working on things and those things get posted to I think the Science Channel     
15:29     
and I think c302 unfortunately we don't have that configured for dorm but we     
15:34     
don't really operate on a issues based system in Diva worm so the openworm     
15:39     
GitHub uh organization is at github.com     
15:44     
openworm and so you'll find here you'll find a lot of things that are beyond evil worm that are uh incorporate the     
15:51     
entire open worm foundation so open or is an a nonprofit Foundation it's a     
15:57     
501c3 and there's an umbrella of projects under openworm that involve simulating uh seans the nematode so we     
16:05     
have a number of different projects going on for biophysics for neural network you know simulation for     
16:13     
development for movement all these things and so we have a number of repos     
16:18     
that you might want to check out there's c302 there's jepetto which is a simulation platform for web- based     
16:26     
applications uh there's Channel worm which is Ion channel specific um vahed     
16:32     
who attends the meetings currently it has a lot of expertise in the area of ion channels and they're you know     
16:39     
modeling the ion channels in the context of seigan neurons we also have a Docker     
16:45     
file which is pinned here so if you're really interested you can run you can download the docker file in this release     
16:53     
0.9.4 you can run it on your own machine you can get a sense you can get a taste     
16:58     
of the different simulations that openworm does and you know if you are     
17:03     
handy with Docker files you can get it to run you do need a bit of memory on your machine but you can get a sense of     
17:10     
all the different simulations so there's a biophysics simulation there's a uh neural network     
17:17     
simulation there's an ion Channel simulation uh one of the things we'd like to do in DVA worm is to develop uh     
17:24     
something to put in that Docker file we still haven't found the right thing but that's something we're looking for doing     
17:32     
and so that's the openworm uh GitHub repo uh the GitHub     
17:39     
organization if you feel like contributing there you can check out their issues and that would I think go a     
17:45     
long way towards uh showing that you're really involved in open source so     
17:50     
openworm also has a website this is our sponsoring nonprofit organization so in     
17:56     
in addition to incf which is sort of our Google summer code organization we have     
18:02     
openworm which is our sponsor sponsoring organization so this is a a a nonprofit     
18:10     
organization uh we have a number of things this is a animation that shows the different things that are going in     
18:17     
an openworm so building the first digital life form open source explore     
18:22     
the worm so there's a worm browser here which is browser. openworm dorg this allows you to see the worm in 3D so you     
18:29     
can zoom in on a model of seans the nematode seans looks like this it's     
18:36     
about in real life it's about a millimeter or so long and it has 302     
18:42     
neurons and 959 cells in the hermaphrodite so it's a a relatively     
18:48     
small system we can look at a lot of things in very high detail in a way     
18:55     
that's not uh doesn't have a lot of biological variation although that's not entirely true as you'll find out if you     
19:01     
come to our meetings you can populate this model with different so you can go     
19:07     
through the layers of the model this is just kind of the cuticle with no nervous     
19:13     
system and then we can move down through this     
19:19     
uh we can move through the layers of this model and we can     
19:25     
see progressively more detail in terms terms of the muscles in terms of the neurons and the nerves that you see in     
19:32     
the nervous system of the worm so you don't see the all cells of the Worm but you do see the nerve neurons the nerves     
19:40     
you see the different aspects of that then you see the muscle and then you see the     
19:47     
epidermis or the cuticle on top so you can go through the different     
19:53     
layers it's almost like looking at a microscopy image where you go through the uh focal     
20:00     
layers but you're dropping things out you're seeing sort of all the aspects of     
20:06     
the worm nervous system and it's it's a lied     
20:13     
structures so that's the open room browser there's also cybernetic which is a biophysics simulator and that's that's     
20:20     
open source and this simulates the worm moving through different types of physical media so the worm moves through     
20:27     
the soil usually U there's dorm so this is something where you can just go to our resources to our website which I'll     
20:34     
show in a minute there's also the open browser neuroml connecto this is the connecto model that H is coded neuroml     
20:42     
there's open source visualization using jepetto so this is a simulation platform and then worm Sim where we also have     
20:50     
another simulation uh mechanical model of the muscular system so the open room browser     
20:55     
is open source it's available on the GitHub uh in one of the GitHub repos so     
21:01     
another thing we have in the GitHub repository open data sets and so we have     
21:06     
rol which is a model of the connectone we have nioo which is are a     
21:15     
series of neuron models these are biophysical models we have the Johnson mailor muscle model we have this gate     
21:22     
modulation model and others so we have a number of things in our GitHub reposit     
21:28     
that are secondary data we have computational models and so a lot of that is available by just simply going     
21:36     
to the GitHub repository and cloning the repository or forking it and working out it for yourself so this is the dorm     
21:45     
repository um this is distinct from the diva learn organization because at this site we     
21:52     
have a lot of our Legacy stuff so we've done we do a lot of stuff with computational developmental     
21:59     
biology and we work a lot on a lot of topics so there are a lot of repositories here that are sort of uh     
22:06     
what we're doing with Theory so those sorts of things aren't as GitHub ready or GitHub friendly but we do have     
22:13     
repositories for them we have a meeting archive here and this kind of goes over our     
22:20     
meeting history since 2020 so we've been on our YouTube channel since January of     
22:25     
2020 and we've gotten you know four years of archives here just about     
22:31     
uh maybe three and a half and we you know we have the topics for each week and the speakers so we've got a lot of     
22:38     
things here it's it's a good historical reference to compliment our YouTube channel so we also have a a set of open     
22:45     
data sets and this is uh the diva worm repository of Diva worm and so it's     
22:52     
dormdorm this has a number of data sets in it you'll find the data sets either     
22:57     
in some sort of CSV file format or an Excel format and the reason for that is     
23:02     
we want to have that we want to preserve that common Del limited aspect to it and so this kind of tells you about     
23:09     
these different data sets so we have a lot of data for uh raw nuclei for cell     
23:16     
birth and death timing uh differentiation trees for     
23:22     
embryo networks reg expression lineage tree data and positional info so we have     
23:27     
a of data sets that you can look at and they're in that very simple format we     
23:33     
also have the other data set that I showed you before which are some of the raw data sets and if you have any     
23:40     
questions please let us know um you can either create an issue on GitHub or talk     
23:47     
about it in the slack Channel or come to one of the meetings we also have something done in 2019 so it might be a     
23:52     
bit dated for a lot of people uh but this is a course we ran on dorm machine     
23:58     
learning so this is a course that we I offered in the fall of 2019 and it was on current topics and     
24:05     
machine learning but related to developmental biology so we had a number     
24:11     
of things that came out of this we had people give lectures we had people give discussion lead discussions and we we     
24:18     
kind of culminated this in a project that was a pre-trained model uh that was sort of the basis for     
24:25     
Deva learn so we did this and you know it was I think it was     
24:31     
really productive in the sense of laying out a curriculum for developmental     
24:37     
biology inspired machine learning or something like that but there are a number of lectures you might want to     
24:43     
check out here some of these are somewhat dated but basically what we're trying to do is apply different machine     
24:49     
learning techniques to different model organisms to different systems and to     
24:55     
see what those look like there's a lecture on input data which is quite good and that's probably independent of     
25:01     
any one technology there's also some things linking artificial neural networks and biological neural networks     
25:08     
and some tutorials of things like concert flow so we might do an update on this course but the content from 2019 is     
25:15     
here and you might find this useful so next up is our website dorm and so this     
25:20     
is where our group uh all of our work is accumulated uh we've been around almost     
25:26     
10 years so our 10 10 year anniversary is going to be on April 11th and I'm going to in a meeting near April 11th I     
25:34     
think it's like April 8th I'm going to go over 10 years of progress and talk     
25:40     
you know have a presentation on that so you're joining the or this organization     
25:45     
right on its 10e Mark and openworm has been around a little bit longer than that openworm celebrated its 10th     
25:51     
anniversary about two years ago so we have a number of resources here this is     
25:56     
where you'll want to check out some of our Publications so we have Publications     
26:01     
page which has our Publications in a number of areas so our group has published a lot of things on     
26:08     
celegans but we've also published things onopa we've published things on the Dion     
26:14     
basilia which Dions are uh elal organisms there single cell we have     
26:21     
comparative development so we have papers where we've done comparisons of different organisms so C elans and zebra     
26:28     
fish SE elegans dropa mice and     
26:33     
East and then we have this paper where we compared seans with a c squirt called     
26:39     
ciona intestinalis and so this this is an interest area of interest for us is     
26:45     
looking at different types of development as well and then finally we have papers on Theory and simulation     
26:52     
type things what they call in silico research so these include things like like     
26:58     
hypergraphs and cognitive morphogenesis and um other types of     
27:05     
things where we kind of really push the boundaries of computational Developmental biology we also have media     
27:11     
and public lectures which can be found off of the education notebooks and media     
27:16     
tab so this kind of goes over some of our public lectures on our YouTube channel and so this talk dimensions of     
27:25     
morphogenesis is something that I recorded recently I've put out a number of uh overview videos so you'll go     
27:32     
through here and you can find different threads of our research that maybe aren't published but still we we're     
27:38     
doing work in that area so we're doing work in different areas of morphogenesis I have a talk on dvo learn     
27:45     
the 10,000 meter view which is a very good overview of dvo learn and a lot of     
27:50     
the software that we're building so this includes Devo graph and you know a lot     
27:56     
of the machine learning work that we've been doing I've also given updates to the openworm foundation so I have     
28:01     
year-to-year updates in here I have some of our work on datom uh some other topics and some of     
28:08     
the work that we've done on networks and Realo networks computational development and neuros simulation you I want to     
28:13     
check that video out specifically if you're interested in D     
28:19     
graph and then we've done a lot of work on networks so I have a number of talks here down a little bit on network     
28:26     
science and embryos and in biological systems uh you know ranging from     
28:32     
embodied hypergraphs to some of the things that we've done with embryo networks and that's you know matches up     
28:39     
with some of our Publications we also have a lot of alumni of Google sumar of code so dorm has been involved in Google     
28:47     
summar code since about 2017 and so I've been the mentor for all     
28:52     
of those classes of people so in 2022 we had four students uh this is not updated     
28:58     
for 2023 but in 2023 we had two students heran shogul and sshma ready in 2022 we     
29:07     
had four students we had wato kamak Kami uh Jang Lee who worked on dor graph and     
29:14     
then Karan Lan and Har Krishna Pai who worked on this digital microsphere     
29:20     
project and so we've had we have a rich history a rich association with Google     
29:26     
summer of code have done a lot of projects and we've kind of combined that all under dvo learn so there's the main     
29:33     
D.A learn platform and then there's dvo graph and we hope to combine those two into one set of releases very soon but     
29:40     
we have to work on some technical details to make that happen and that's where you come in if you're so     
29:45     
interested we also have a number of data sources so this is not complete with respect to all that's we have available     
29:52     
so in addition to what's on the in the openworm repositories we have these     
29:57     
uh other uh data sets these are available at fig share or sometimes     
30:03     
they're on GitHub and sometimes they're just available online they're online     
30:08     
resources so you know we do a lot of things with um sort of secondary data so     
30:15     
it's been collected by other groups and we've built a version of that a cleaned     
30:20     
up version of that those data or sometimes there'll be things that we've generated from you know experimental     
30:28     
Evolution or from uh simulations or whatever so we have a number of things     
30:33     
that you might find of Interest celegans we have division event data which is     
30:38     
where you look at the divisions and development we have the Epic data set which is raw microscopy data which     
30:46     
allows you to look at the sequence of events in cell division and cell differentiation and C Elegance we have     
30:54     
this other uh digital development data set that uh allows you to look at     
31:00     
lineage phenotypes and Define those we have data on our uh D.A worm GitHub     
31:06     
repository as well and that's different from the D.A learn repository D.A worm     
31:12     
has a number of data sets which I think are linked here but uh those those can we can also     
31:19     
discuss what data you actually need for certain to solve a certain problem so we     
31:25     
should talk about these things don't just go and grab data and start using it but these data are available for you to     
31:32     
look at to get an idea of what you might want to do we also have gene expression data a lineage tree database this is the     
31:40     
original Source paper on the lineage tree for cgans this is a little bit more uh data     
31:47     
on like sub lineage differentiation so they're different data sets for the same thing and you can kind of get a sense of     
31:54     
what the collected data look like for that thing thing uh we also have positional information data so the     
32:01     
position of specific cells in an embryo and we have data for other     
32:06     
species like ciona intestinalis roph and zebra fish finally we're also affiliated     
32:13     
with the orthogonal research and education laboratory this is an organization that does uh research in     
32:21     
computational biology but we also do things in simulation cognitive science     
32:27     
and other areas as well so we run a a meeting called the Saturday morning     
32:32     
neuros Sim group and that's where we talk about neuros simulation and some of the topics around     
32:38     
neuroscience and simulation computational methods and very broadly     
32:44     
construed we talk about all sorts of things actually but focused on those things so that's something you might     
32:51     
want to be interested in but this is our website for the orthogonal research uh lab we have a a number of Affiliated     
32:58     
projects so Diva worm and openworm are part of that we're also interested in neuro AI open source informatics and so     
33:06     
forth and we have a number of opportunities through there as well we have two projects through the orthogonal     
33:13     
lab this summer we have one project on virtual reality and augmented reality     
33:19     
and building assets for that but we also have one on open source sustainability which is the     
33:26     
sustainability of open source projects so if you don't find what you want in evog graph you could apply to one of     
33:32     
those projects as well and then finally I want to highlight our YouTube channel so this is our YouTube channel where we     
33:38     
have a lot of our meetings I think all of our meetings are posted here we also have a number of talks and we have a lot     
33:45     
of playlists so let's look at the playlists so we have a number of playlists that you know they're     
33:51     
basically conference talks uh you know just inform Al talks     
33:58     
about things our lab meetings different tutorials um and so we do a lot of     
34:04     
things we do a lot of things with complex systems dynamical systems we participated in Dynamics days we     
34:11     
participated in the network science Community uh we participated in some machine learning     
34:18     
communities and of course we do a lot of stuff with computational developmental biology theoretical Concepts like het     
34:25     
prony and other types of things so we have all of our channels here I would     
34:30     
take a look at this YouTube channel just to get a sense of what we do what we've done in the past and like I said this is     
34:36     
the 10th anniversary of Diva worm so later this year in April I'll be going     
34:43     
over that history more detail to give you an idea of where where we've been and where we want to go so thank you for     
34:49     
paying attention and good luck for things accordingly and ask questions     
34:55     
accordingly okay looks like like we got a number of people here yeah paky and     
35:00     
Sara and vahed and Morgan so hello and Susan posted a citation here     
35:10     
okay um I'll send uh I'll send you the paper okay that sounds     
35:18     
good uh Ved where did you want to give an update     
35:25     
or uh [Applause] hi for this week uh not that much update     
35:34     
I'm I'm going to uh maybe because I was a little busy with something else this     
35:40     
week but uh maybe in the next week I will uh I will uh pre notify you and     
35:48     
then we of course uh if that okay yeah yeah just make sure you're on     
35:57     
track uh getting things that you need yeah for sure yeah I've been discussing     
36:03     
something with Pat so to be to see if it would be     
36:08     
possible to connect give to C2 okay uh     
36:14     
but uh practically I'm still looking to see where in the code uh we shall uh     
36:23     
start with and then we would go on     
36:28     
okay that sounds good yeah that would be good if we could have some sort of connection between the two um be nice     
36:36     
yeah for sure so I'm going to get into so in the group we've talked uh we have a long-standing interest in something     
36:43     
called cellular automa and cellular automa are these uh they're these grids you can build where     
36:51     
you have cells and they have neighbors and they form neighborhoods and the idea is you can do     
36:57     
discrete computation on them which means that you can simulate a process you can     
37:02     
model pattern formation and other things by having these cells interact with each     
37:08     
other and you know this has been a tool that's sort of abstract to a lot of problems but yielded some really     
37:14     
interesting results in this case interesting means that there's a lot of like you know uh     
37:21     
things that look lifelike or they look uh like they're you know sort of these     
37:27     
emergent patterns that form and people you know they've been really valuable     
37:33     
for a number of fields so today I'm going to talk about something called Rule     
37:39     
30 and you know where it comes from and then how we can apply it to uh different     
37:46     
biological problems we've talked about this for many uh several years actually     
37:51     
we did some early work on cellular automa back in like 2016     
37:57     
uh and we you know we've we've kind of not talked about it recent years but uh     
38:03     
it's still very interesting work so I didck sent me some papers uh on someone     
38:10     
named Paul B Green who is a plant biologist and we'll get to that in a     
38:15     
little bit so what is Rule 30 so this is Rule     
38:20     
30 and you can see these cellular automet here there are these grid structures where you have these cells     
38:28     
and each cell is autonomous in the sense that they have their own set of rules     
38:34     
and these rules tell the cell how to how to behave given the behavioral state of     
38:39     
its neighbors so for example this cell here is you know the the cells can be in     
38:46     
a state either on or off in this case they can be gray or white and it's the same thing it's a binary switch that     
38:53     
gets triggered by these rules being satisfied so this cell here has uh a number of     
39:01     
neighbors they're all adjacent cells so in this case it can have a neighborhood of four it can have the cells to the top     
39:09     
to the bottom to the left or the right we're going to have nine neighbors or eight Neighbors which are all the cells     
39:16     
touching that cell and so the neighborhood definition is important     
39:22     
because this cell will take the inputs of or it will observe the state of all of its neighbors and then produce an     
39:28     
output State based on that so you know this cell has uh six neighbors that are gray and     
39:37     
two neighbors that are white and so the cell must have a rule that says if any     
39:42     
one of your neighbors is white then remain white or turn remain turned on or     
39:49     
if uh more than one of your neighbors is white remain white remain turned on so     
39:57     
you know you can set up all sorts of rules in these cells and then there's this adjacency effect where its     
40:03     
neighbors have neighbors have neighbors and each cell having its own     
40:08     
rules you know means that they kind of behave not necessarily in the same way     
40:15     
but in a similar way so each cell will either turn on or turn     
40:21     
off and you know make things more interesting you might have cells that have a that's determined by some     
40:28     
stochastic process so it's like flipping a coin whether it's gray or white and so     
40:34     
then that kind of makes a difference in terms of local neighborhoods the state of the local neighborhoods and then that     
40:41     
propagates across this grid so this is Rule 30 this is a this is uh this model     
40:48     
that's run over time so you have all these cells they have their own rules they have their own interactions with     
40:53     
their neighbors those interactions not only remain in those neighborhoods that propagate across the grid and you end up     
41:01     
over time with these these rules refreshing the states of the cells refreshing and you end up with this     
41:07     
pattern so over time you get a pattern from what was basically before either     
41:13     
nothing where the entire grid was one state or Randomness where cells were     
41:18     
randomly distributed in terms of their state and so rule 30 is really they're     
41:24     
actually Steven Wolf from uh back in around 2002 published a book     
41:31     
where he has like a over a hundred rules that can have you know you can have these different rules uh that exist uh     
41:40     
you know and these rules of course are based on the rules of the cells and what those rules say so there are over a     
41:46     
hundred rules that that yield different patterns if you run these simulations over time and this is something called     
41:53     
fundamental computation in other words what he's looking for here is sort of the fundamental aspects of computation     
42:01     
fundamental aspects of of pattern formation and the analogy is is that you     
42:06     
can use a cellular autometer to model any type of system uh probably just     
42:12     
limited to discrete systems but it should be Universal across different systems so we have this rule 30 it     
42:19     
produces nice patterns it produces them on this grid you have this uh Matrix     
42:25     
that shows you kind of how this works in a three-bit     
42:31     
register so we can see with a three-bit register we have uh all the possible     
42:37     
States from 0000 Z to 111 so you know we we flip bits across these three binary     
42:45     
States or these three binary values and we get eight states we get zeros and     
42:50     
ones and the output here is is based on you know a number of Criterion     
42:57     
uh you know let's so okay the new state for Center cell would be zero if the     
43:05     
current pattern is 11 one one one one Zer results in a zero one Zer one     
43:10     
results in a zero z z z results in a zero and then all of the other states     
43:15     
result in a one and so you know there's something going on there with the rule     
43:21     
so if the left Center and right cells are denoted pqr then the corresponding formula for the next state of the center     
43:27     
cell can be expressed as P exclusive or which is a logical function Q or R and     
43:35     
so it's you know in this case you're using a logical function to update to     
43:40     
the next cell it is called Rule 30 because in binary we have this uh string     
43:47     
and then that equals 30 so this is why they call it rule 30 uh so this is basically the rule 30     
43:55     
and you can have all sorts of patterns that emerge if you run the simulation long enough this is a really complicated     
44:02     
pattern of rule 30 this is where it really gets packed in and you get these sort of different uh shaped triangles     
44:10     
embedded in the pattern so it's an interesting pattern but what's interesting about it even more is that     
44:17     
it's not just something that you see in a cellular automaton you actually see it in uh snail     
44:23     
shells so if we look at this uh conus textile shell which is a a species of uh     
44:33     
of uh shelled mollusk we can see that we have the same pattern or a very similar     
44:39     
pattern emerge and so the reason I bring up rule 30 at all is because a it's this     
44:45     
Universal form of computation we can explain it we know how it's     
44:50     
generated B we see this P we can replicate this pattern and has features     
44:57     
that match something that we see in nature so you know you might think well     
45:03     
okay well maybe nature does the same thing maybe all the cells in this in     
45:08     
during shell formation the cells do the same type of interactions they have these autonomous rules and they form     
45:14     
these patterns which would be nice if that were the way it worked but we don't     
45:20     
exactly know the way it works or at least we don't have you know we do have some mechanisms worked out as we'll see     
45:27     
but we don't know exactly how that would work you know why would that work uh so     
45:33     
that's that's an interesting thing it's an interesting observation and you know at least it's analogically correct in     
45:41     
that they both look the same but did they get there in the same way so I have some papers     
45:51     
here on rule 30 so this is uh from Walt the wal from matless of simple programs     
45:58     
so again this is something Steven wlr has worked     
46:03     
on and you know he has all these rules worked out kind of showing the rule     
46:09     
properties uh simple initial conditions you can randomize the initial     
46:15     
condition and you can you know there's The Ensemble properties and the finit State Properties basically ways to     
46:23     
analyze it and understand it so we have the mathematical tools we need to understand it more or     
46:30     
less we talked about this Wikipedia     
46:36     
article this is a paper actually that talks about the complex Dynamics emerging in rule 30 with majority memory     
46:43     
so not only does rule 30 replicate things that you see in biology and it produces complex outputs     
46:51     
that look like they're pattern formation but they also have this sort of comple Lex Dynamics on their own and     
46:57     
so that might lead to things like you know uh different types of uh uh     
47:04     
different types of uh systems that can be simulated with this so there are a lot of complex Dynamics this is complex     
47:12     
Dynamics emerging in rule 30 with majority memory so there's a memory component that gets uh added to rule 30     
47:19     
and then they look at this in this paper uh you know how this works so the ab     
47:25     
ract for this uh is in cellular autometa with memory the unchanged maps of the     
47:31     
conventional cellular autometer are applied to cells endowed with memory of their past States in some specified     
47:38     
interval so they have this rule 30 they apply it to a cellular     
47:43     
autometa they you know the rules get updated the pattern is sort of emerges     
47:48     
or changes accordingly and then but then there's also this memory so now each     
47:55     
cell aside from having an autonomous rule also has a memory of its past     
48:01     
States we Implement rule 30 automative with a majority memory and show that     
48:06     
using the memory function we can transform the Quasi chaotic dynamics of     
48:11     
classical rule 30 into domains of traveling structures with predictable     
48:16     
Behavior so as you saw in the Wikipedia article they talk about uh chaos and     
48:24     
chaotic Behavior so they talk about rule 30 meeting the     
48:29     
rigorous definitions of chaos proposed by deanan nutson in particular Dean's     
48:35     
criteria according to that rule 30 displays sensitive dependence on initial conditions which is something that you     
48:42     
see in Chaos Theory basically wherever you start your system if you start your     
48:48     
system here it's going to yield a much different pattern than if you start your system here it just depends on what the     
48:55     
initial condition is so if I randomize my cells across the grid it gives me a     
49:00     
much different uh result than if I start with something that's seated to be like     
49:05     
sort of the quazi pattern so it's an important point because we don't you know we don't know     
49:12     
necessarily the developmental origins of rule 30 or seashells for that matter I     
49:18     
mean we know the the development of Origins we don't know like if that's     
49:24     
something that's just random or if it has like a a sort of a reason why it's     
49:29     
there so that's and of course in chaos of course we have you know a lot of     
49:36     
interactions and we have a system that is uh has the sensitive dependence but     
49:43     
can also you know there's this whole L uh language in in dynamical systems and     
49:49     
chaos theory that describes sort of the boundary between Order and Chaos and     
49:54     
what that is so so chaos is a very uh there's a very deep set of properties     
50:00     
and it's not just saying that it's chaotic uh you know but we'll leave that aside for     
50:06     
now so in this paper they uh can transform quaza chaotic dynamics of     
50:12     
classical rule 30 so rule 30 you'll see these patterns form and sometimes you'll lose them sometimes you'll lock on to     
50:19     
certain patterns given the uh a certain initial condition and things like that     
50:24     
so it's not just random Behavior it's it's ordered Behavior but it it achieves     
50:29     
it in a chaotic way uh and so they transform this into     
50:36     
domains of traveling structures with predictable behavior and so that means that you have not only these fixed     
50:43     
patterns but that you get patterns that move you know you things that move around and they're pattern so this is     
50:51     
predictable behavior that we can recognize as a pattern we analyze morphological complexity of     
50:58     
the automa and classify dynamics of gliders particle self- localizations     
51:04     
gliders are things like you know different clumps of cells that sort of     
51:09     
move across the grid and they Glide across the G grid together meaning that     
51:15     
that rule sort of propagates across the grid all the cells have these underlying     
51:20     
rules the same rules but the activity rather propagates across the grid     
51:26     
uh so this is one of the features that really people kind of point to to say this really looks lifelike these Glide     
51:32     
the existence of these gliders uh in the memory and rral 30 we     
51:37     
provide formal ways of encoding and classifying glider Dynamics using de Bruin diagrams Solon reactions and     
51:45     
quasichemical representations so this is a classic Anam Andi adamatzky paper and that it     
51:52     
has a lot of this unconventional computation in it and they do this en codian classification of these     
51:59     
gliders so I don't know if they give an example the glider this is uh the effect     
52:05     
of majority memory of increasing depth on rule 30 starting from a single sight     
52:11     
live cell so this gives you this ahistoric summary and then you have this     
52:16     
memory where there's this depth so you get something that propagates outward     
52:21     
you get these different effects of memory so the pattern changes the Implement     
52:27     
memory uh so this is the typical behavior of     
52:34     
rule 30 where a single cell in state one leads to a chaotic State that's here on     
52:39     
the left and then the second configuration shows automaton behavior from random initial condition with     
52:46     
initial density of 50% for each state and that's on the right both automata     
52:51     
evolve on a ring of 497 cells and so you can see the differences the patterns     
52:56     
with the different initial condition so debrin diagrams are     
53:02     
basically these trees or these graphs that show kind of the states uh for rule     
53:08     
30 so they break down rule 30 into this uh diagram and these these a lot     
53:13     
actually in uh in genomics in bioinformatics so these are useful tools     
53:24     
um and then this of course is a a much larger de debrin diagram that shows rule     
53:30     
30 as it     
53:35     
evolves and so yeah we get this sort of memory state so people have uh simulated     
53:41     
rule 30 and again depending on the initial condition it gives you a different set of patterns but we also     
53:48     
have this majority memory aspect that can show you know significant Evolution     
53:53     
across the run so you can run this rule 30 you can get all sorts of random     
53:58     
States but you can get these highly patterned states that look like this so it's clearly more than just an     
54:05     
analogy with Biology you can actually do a lot of analysis of rule 30 and see if     
54:11     
this is something that looks like it's biological if it's replicating things in the biological World okay so we have     
54:18     
these uh this paper goes on and talks about some of the ways we can analyze rule 30 and so you know we might say     
54:26     
okay well what are the mechan computational mechanisms in an organism that might lead to this and that's what     
54:32     
we're going to get into next I just wanted to finish off with this this is uh a little image of rule 30 on for uh     
54:40     
cell neighborhood just showing the different way the different states evolve     
54:47     
so you know in seashells of course we get this kind of     
54:54     
patterning and you know sea shell development occurs kind of     
55:01     
from you know from a early stage and you get these shells that form so this is     
55:07     
showing a shell and how it's creating from the inside out and it's forming     
55:13     
this pattern so it's showing this picle shell and it's wrapping around this is     
55:18     
this animation is just showing how this pattern kind of recedes around the shell     
55:24     
so so this pattern kind of the the cone the conle uh shell unfurls from the center     
55:32     
and it comes outward and so this whole surface then gets patterned and you know you might say     
55:39     
well okay you have cells here that uh behave like this they interact with their neighbors and they form these     
55:46     
patterns and then you get this shell and the patterns might be useful for some     
55:52     
purpose we don't know but you know they may basically Bally form like rule 30 so what are the mechanisms that kind     
55:59     
of govern this is this all cell autonomous or is there something else going on     
56:04     
here so this is a paper was published quite a while ago this was in um     
56:12     
2009 and this is actually by a number of neuroscientists so now we're throwing neuroscientists into the mix     
56:19     
here and this paper is the neural origins of shell structure and pattern     
56:24     
and aquatic mollusks so this is uh the abstract reads we present a model to explain how     
56:31     
the neurosecretory system of aquatic mollusks generates their diversity of     
56:36     
shell structures and pigmentation patterns the anatomical and physiological basis of this model sets     
56:43     
it apart from other models used to explain shape and pattern so this is where they're proposing a model for the     
56:51     
generation of these shell structures and their diversity and their pigmentation patterns so this is actually a neuros     
56:58     
secretory model so it doesn't necessarily match up with rule 30 at least initially but they're going to     
57:05     
produce a model that kind of explains how this works and this is going to be     
57:11     
you know sort of tied to the brain of the mes or the neural mechanisms so this     
57:17     
is interesting the way they're doing this uh the anatomical and physiological basis of these models sets it apart from     
57:23     
other models the model reproduces most known shell shapes and patterns and accurately     
57:29     
predicts how the pattern Alters in response to environmental disruption and subsequent repair so you know we didn't     
57:36     
see an example of rule 30 being repaired so that you know so rotometer one could     
57:43     
take a chunk out of it and like watch the thing regenerate so you could reset     
57:49     
a number of the cells to zero or to one state or another and you could watch the     
57:54     
pattern fill in or maybe it wouldn't we don't really know because I don't think anyone's done that particular experiment     
58:02     
but the idea is that in biological systems we get this sort of repair mechanism and the pattern gets repaired     
58:09     
in a certain way they also have environmental effects so MKS are very sensitive to     
58:15     
environmental conditions fluctuating they live in in the uh they live in in     
58:21     
estuaries so you have water chemistry and temp that are very important in kind     
58:26     
of shaping the development of these structures so that's the kind of thing we want to have in a model as well     
58:34     
finally we connect the model to a larger class of neurom models and so that's what they do um so they talk about let's     
58:43     
see um they talk a little bit about the biology of the     
58:48     
shells uh early attempts to reproduce shell patterns use cellular automa models in which arbit rules determine     
58:55     
the pigmentation of cells on a grid these are the citations although they can reproduce some observed patterns     
59:02     
these models have shed little light on how such patterns actually arise in the animal so inspired by the chemistry of     
59:08     
diffusing morphogens mhart and co-workers and these are the citations here used a variety of different     
59:15     
diffusion reaction models to reproduce a wide variety of shell pigmentation patterns so diffusion reaction models     
59:23     
are the same type of models that we see with respect to uh uh Turing     
59:28     
morphogenesis so if you've heard of Turing morphogenesis that's what diffusion reaction models are and so     
59:35     
there are a number of classes of that we have a lecture on the YouTube channel uh     
59:40     
that I put out earlier this year in January on morphogenesis and I talk     
59:46     
about some of the different models of morphogenesis for one Dimensions two dimensions and three dimensions so this     
59:53     
is an interesting thing to go back back to and look at in light of this paper and some of the rule 30 stuff so what     
1:00:00     
they're saying here is that rule 30 is you know it although it produces patterns that look biological it isn't     
1:00:07     
sufficient to really explain how they arise and so then they T turn to these     
1:00:12     
diffusion reaction models that can re also reproduce a wide variety of shell pigmentation     
1:00:18     
patterns although no experimental evidence has been found for diffusing morphogens in patterning     
1:00:27     
the models can be viewed as an incomplete analogy for neural activity so this is again something that invites     
1:00:34     
sort of a neural explanation involvement of the nervous system we don't really have a mechanism worked out so they sort     
1:00:41     
of you know they sort of rival the rule 30 model or the rule 30 approach but     
1:00:47     
they don't quite get there so both the neuro and and diffusion reaction models allow     
1:00:53     
different ways of describing the phenomena of local excitation with lateral inhibition and so that's what     
1:01:00     
they're interested in is this local excitation with lateral inhibition so     
1:01:05     
basically if we go back to rule 30 we can model that with rules that say you know in our neighborhood we have certain     
1:01:11     
rules for excitation we have certain rules for inhibition maybe if our lateral neighbors are excited then we're     
1:01:19     
inhibited we we're in a different state than our neighbors if uh majority of our neighbors are turned on then we also     
1:01:26     
turn on rules like that we can model this kind of uh excitation and inhibition but we can also model it with     
1:01:33     
uh like connectionist models or neural network models and so that's some of the other stuff that people have done     
1:01:40     
working on these kind of Concepts um and so this is this is the thing we want to     
1:01:45     
do though we want local excitation with lateral inhibition uh Ernest Ernest mock uh     
1:01:51     
first described this phenomena to explain the visual illusion now called mock bands so mock bands are     
1:01:57     
these visual Illusions uh that you can look up U and you know he did a lot of     
1:02:02     
early psychophysics and you know it's just something that you'll see in visual Neuroscience a     
1:02:08     
lot and emphasized the properties of this model of enhancing boundaries so uh     
1:02:15     
local excitation with lateral Ro aition allows for enhancing boundaries we also     
1:02:21     
see this with uh reaction diffusion we also see this with reaction diffusion     
1:02:28     
models and the way they behave as well early a century later alen Turing     
1:02:34     
showed how Lai which is the acronym for local excitation with lateral inhibition     
1:02:41     
could be modeled by systems of nonlinear diffusion reaction equations     
1:02:47     
this property is expl by later workers most notably Murray and mhart to model     
1:02:52     
an extraordinary range of biological p patterns and so this is be the re     
1:02:58     
diffusion reaction models have become an allpurpose LLY metaphor in many domains     
1:03:03     
where wherein the underlying physics are clearly not diffusing substances all these models exhibit spatial     
1:03:09     
instabilities that lead the spatial patterns so we get the spatial patterning we but we first need spatial     
1:03:15     
instabilities and we don't necessarily need diffusing substances we just need an underlying physics of inhibition and     
1:03:23     
excitation and so we can look at that we can see in     
1:03:28     
development we can get this sort of thing we get spatial instabilities those things propagate into spatial patterns     
1:03:34     
like we saw with rule 30 and the propagation of things from one neighborhood to other neighborhoods or     
1:03:41     
gliders which move across the grid uh the neural shell model presented     
1:03:47     
here combines spatial with temporal instability because the mantle consents previously laid patterns by looking     
1:03:54     
backwards in time so they actually have this neural shell model that it looks backwards in time and so then it brings     
1:04:01     
in some aspects of memory in this case you're not adding a computational memory     
1:04:06     
so much as you're adding in some neural mechanism uh LLY and time is equivalent     
1:04:13     
to a refractory period that leads to temporal oscillations um and so M heart's     
1:04:20     
diffusion reaction models have succeeded in reproducing almost all the patterns quite accurately and we can hardly do     
1:04:27     
better here our goal however is not to merely reproduce the patterns but to show how a singles neural network model     
1:04:34     
based directly on the mantle Anatomy can capture all of the pattern complexity as     
1:04:39     
well as constructing the shell shape and relate that model to a broader class of     
1:04:44     
experimentally observed neural network Behavior so this is interesting how they kind of bring this different type of     
1:04:51     
model to bear on this problem so they argue that this is a neurose     
1:04:57     
secory process uh that their secretions in the periostracal groove which is a     
1:05:04     
part of the anatomy of the mesk are controlled by underlying neural networks     
1:05:10     
synapsing on the secretory cells so we have a neural network in the brain of the mesk and it's synapsing on secretory     
1:05:17     
cells and it's actually controlling the release of secretions that produce these     
1:05:22     
patterns so it's actually you know if we can think of like a rule cellular automous cell implementing rule 30 rule     
1:05:31     
30 in this case is actually being triggered by say like some small neural     
1:05:37     
network that's synapsing onto that single cell and in fact you can do this     
1:05:43     
uniformly across the Grid or you can do this in other ways and so that's what they're kind of arguing that there's     
1:05:49     
this network mechanism or this neural mechanism that's kind of controlling these secretions and their pulsation and     
1:05:57     
you know managing interactions between different cells the activity of this neural     
1:06:02     
network is stimulated by the existing pattern of shell deposition and pigment at the mantle Edge so we saw that     
1:06:09     
animation where the the shell was scrolling outward and we saw that you know the mantle Edge is sort of the the     
1:06:15     
middle of the shell and as it comes out you're sort of refreshing your state so     
1:06:22     
as this as the the shell kind of develops kind of coming outward like that you get you know uh previous states     
1:06:30     
are are being consulted I guess in a way that determines the next state so in a     
1:06:36     
sense you know it's as dependent it's as sensitive to initial condition is Rule 30 but it's not the same thing because     
1:06:44     
you do have this memory that's built up over the course of shell     
1:06:50     
deposition the shell is constructed by periodic usually daily but BS of secretion so this is a pulsatile thing     
1:06:56     
where you get these daily bouts of secretion and you know thus it's it's     
1:07:02     
probably influenced by the environment of the mollusk so it could be What temperature temperature gradient or it     
1:07:09     
could be the uh water chemistry or things like that can that can affect it     
1:07:14     
these periodic increments are robust against many kinds of environmental variations but not all of course you you     
1:07:20     
always have environmental variation but you know it can affected by large scale     
1:07:26     
fluctuations we model the secretion in Daily steps where in the pattern of each day's layer of secretions is a function     
1:07:33     
of pre-existing layers and so this is an example here of     
1:07:39     
the shell making Machinery you have this dorsal epithelium here you have     
1:07:45     
secretory cells here you have the shell kind of coming out from that secretory cell you have sensory cells synapsing on     
1:07:52     
this uh perio strial Groove you have the circum palal axon     
1:07:59     
and then you have the pallial nerves so the secretory cell and the sensory cells are linked by this uh network of I guess     
1:08:08     
two neurons and they're kind of linking those two things together so it's sensing things and then it's secreting     
1:08:15     
things basically the small network of cells and this is all within this perio     
1:08:21     
strial Groove so it's producing a pattern and that's that's what we have so that's     
1:08:27     
the shell making machinery and then of course we have this lateral inhibition so we see that like in the Shell we can     
1:08:34     
get these Stripes so lateral inhibition and Boundary formation just mean that     
1:08:39     
you have you know like you have in ter morphogenesis you have this these     
1:08:45     
gradients that come together and they form a boundary because they kind of uh sort of need at a point and there's sort     
1:08:53     
of this sharp distinction between the two gradients uh in this case you get lateral inhibition in certain conditions     
1:09:00     
under certain conditions and you get the striping and so you can see that local     
1:09:05     
excitation and lateral inhibition work hand in hand you get this lateral inhibition here and local excitation in     
1:09:12     
the middle and that's where you get these bands and so you've got this worked out     
1:09:17     
in terms of a model they've defined an activation inhibition signal and then     
1:09:23     
you see this new pigment deposition here this is an example of sort of the     
1:09:29     
structure in terms of space so you have the amplitude here and the pattern so you you can go across space you can go     
1:09:37     
across time of course this unfurls over space and time the structure is actually a spao temporal structure uh so this is     
1:09:45     
an interesting so this is these are spiral-shaped     
1:09:52     
shells and then they show this in terms of dynamical systems turning bifurcations     
1:09:59     
hop bifurcations which are dynamical systems tools um and then we have this Turing hot bifurcation so we have these     
1:10:06     
dynamical systems that result or these dynamics that result from a lot of this     
1:10:11     
activity we can analyze this using dynamical systems theory we can also     
1:10:16     
look at the outcome in different species and actually we see a lot of different a     
1:10:22     
real large different Verity of patterns that result from these kind of     
1:10:29     
mechanisms okay so that's uh enough about that paper I did want to talk about one more set of things and this is     
1:10:35     
in phot taxis so I misspelled phot taxis in this but uh so filot taxis are in     
1:10:43     
plants and it's the way in which leaves are arranged in bot     
1:10:49     
taxis uh so the way that leaves are arranged in spiral p patterns and other types of branching patterns that uh     
1:10:57     
they're basically Leaf arrangements and so a lot of times F attacks this are these sort of you know they occur in     
1:11:05     
these spirals like this or they occur in these uh oppositional branching patterns     
1:11:11     
so phot taxis is from the Greek meaning arrangement of leaves phot taxi is the     
1:11:17     
arrangement of leaves on a plant stem and you get sometimes you get these spirals but you get other patterns as     
1:11:23     
well so this is basically you know as happens     
1:11:28     
in every in a uh plant you get these kind of uh Leaf     
1:11:33     
arrangements and it really depends on sort of the way that morphogenesis proceeds as to what you get so uh you     
1:11:41     
know with an opposite leaf arrangement two leaves arise from the stem at the same level and at the same node which is     
1:11:46     
here so in opposite sides of the stem an opposite Leaf pair can be thought of as     
1:11:52     
a whirl of two leaves so you see this this complex WHL here which looks pretty     
1:11:58     
uh dense it's just the same type of mechanism as you see here where you have     
1:12:04     
these opposite leaves kind of shooting out at different nodes so these are the nodes here where you have these leaves     
1:12:11     
that emerge you'll F you can find the nodes in this crisscrossing spiral as well if you look and that's basically     
1:12:17     
how this this uh process works so you have dis uh disas file taxis which are     
1:12:24     
the two ranked re Leaf Arrangements which are these examples here and then if successive Leaf pairs are 90 a part     
1:12:31     
this habit is called desate and or desit it is common in members of the fam     
1:12:38     
these families some families of plants uh desit filot taxis also occurs     
1:12:45     
in a number of other uh order or I guess these are uh gener many species have     
1:12:52     
just have just two fully developed leaves at a time the older pair folding back and dying off to make room for the     
1:12:59     
desly oriented New Pair as the plant grows so there are a lot of different ways that this can happen uh the point of this though is to     
1:13:06     
talk about some of the sort of the unified rules that that occur so there's     
1:13:11     
this paper the unified rule of file attacks is explaining both spiral and non-spiral     
1:13:16     
Arrangements uh this paper talks about some of the leaflike appendages uh and how they're organiz     
1:13:24     
so they're organized as spiral and N spiral Arrangements um the Adaptive reason for     
1:13:31     
this morphological convergence is unknown and so in this paper they talk about the different angles of     
1:13:38     
arrangements and how these can be sort of uh they're sort of mathematically     
1:13:43     
optimal uh they talk about the the golden mean here but you know these are     
1:13:49     
things that of course like we talked about before with rule 30 there's this Universal computation that seems to be     
1:13:55     
at play here and so they propose unified rule of fot taxis to explain both types     
1:14:01     
of arrangement in this case the developed Le the developed leaves form vertical rows along the stem and the nonsp     
1:14:09     
arrangement nent to develop leaves always follow this rule so that the number of leaf rows is kept constant     
1:14:14     
irrespective of stem growth and the SP rule Arrangement developed leaves attain this rule by adjusting the Divergence     
1:14:21     
angle from the golden angle so they give this sort of mathematical     
1:14:28     
explanation then there's the work of Paul B Green which dick talked about he brought this up to my attention and I     
1:14:35     
did find some papers from Paul be green we were trying to find I don't remember what the conversation was but we did     
1:14:42     
find a number of paper I did find two papers by Paul B Green that have to do with these phoac     
1:14:49     
patterns and this is one from the Journal of theoretical biology characterization by geometrical activity     
1:14:56     
at the formative region and this kind of talks about some of these uh you know     
1:15:02     
aspects of viot taxis and kind of getting at um so I guess he was a plant     
1:15:08     
biologist so you know they were interested in sort of again the Fibonacci series and describing bio     
1:15:15     
attacks as using that mathematical Tool uh but there are a number of diff     
1:15:21     
other types of uh uh patterns that you find in nature helical sequences and     
1:15:28     
other things and so there's a circular aspect to it that they they kind of talk     
1:15:33     
about here um so this is the tool they're using for vot taxis are these um     
1:15:41     
these Fibonacci sequences and then this other paper on the me mechanism of Des     
1:15:47     
Des phot taxis biophysical studies of the tunical layer of vka major which is     
1:15:52     
a species of plant and so they're they talk     
1:15:57     
about uh you know more of this they talk about sort of the geometry of the plant     
1:16:04     
and how that uh responds to the environment so it's interesting uh work     
1:16:11     
but it still leaves open this question about rule 30 and about how we model     
1:16:17     
biological things so you know is Rule 30 maybe something that's sufficient for modeling these kind of phenomena could     
1:16:24     
we just get away with using rule 30 and be good or you know do we need to adopt     
1:16:31     
a model that's more based in biology and you know how do they interact so you     
1:16:37     
know we've we've been introduced to rule 30 and that sort of explains the phenotype the mechanism for seashell you     
1:16:46     
know uh formation some people argue has a neural component and so there are a lot of aspects of     
1:16:53     
uh lateral inhibition that planned that we also can go to more traditional     
1:16:59     
models of morphogenesis like Turing morphogenesis reaction to fusion and     
1:17:05     
those serve well but they don't explain everything and then we can turn to biot     
1:17:10     
taxis and look at how people model that and they model that very differently and they model that with a Fibonacci     
1:17:16     
Sequence and so all these models you know you have to think about the consequences like can you get uh uh you     
1:17:23     
know complex Dynamics out of them can you understand sort of the way that these things develop in terms of the     
1:17:30     
Dynamics and not just like static snapshots so that's that's uh my     
1:17:37     
overview of rule 30 and some of the things that are related to     
1:17:44     
it yeah that came in welcome     
1:17:50     
dick so do we have any comments or questions about     
1:17:59     
that would you like my pictures of shells of what shells yeah that' be good     
1:18:06     
I have took some pictures of dick shells oh yeah yeah the     
1:18:11     
shells well I was I found my found this um I'm supposed to send     
1:18:19     
this to you with images of eggs and shells okay yeah that would be good be     
1:18:27     
good all right uh I'm in the process of contacting Tam dick I did get your email     
1:18:33     
then so I'll get i'll get to that yeah so yeah we've had this uh dick     
1:18:40     
has wanted to do some experiments with shells where you mount them on a mount and you rotate them around and you do     
1:18:47     
three-dimensional Imaging the surface so you get an account of like different shells and what their surface looks like     
1:18:54     
and that would be kind of we never really found the right technology to do that uh in the way we want to do it     
1:19:02     
so um my images are just with that 3D     
1:19:07     
microscope so uh it doesn't do depth the way I want it to and it's only three     
1:19:14     
megapixel cameras and I would like um better cameras yeah oh dick corrected me     
1:19:22     
in saying it's a 2d unwrapping of the shell so you take images of the shell and you can unwrap it into a 2d or     
1:19:28     
unfurl it into a 2d surface it's like taking the 3D and making a     
1:19:35     
2d but that requires a specific way of doing it um yeah yeah you'd have to take     
1:19:42     
my images and map them onto a surface and then you'd have to take the surface     
1:19:49     
and unwind it yeah yeah yeah there's also like projections so like you know     
1:19:55     
when you take a surface of the or when you take like the the world of course as a globe and you take the surface of the     
1:20:02     
globe and you flatten it out to make a two-dimensional map of the world you have to choose a projection to preserve     
1:20:09     
the features and so you know there are a lot of projections you can use and they use this and other things as well in     
1:20:16     
geometry and so those projections basically preserve what's happening at the poles and align them with what     
1:20:22     
happening at the equator and yeah but that's yeah that's that's a different thing so     
1:20:30     
Susan's he says no Susan just take the closest column and image it each angle     
1:20:36     
so well I just used my camera and took sequential pictures     
1:20:42     
of each side so that's four um one on the top four at this angle and four at     
1:20:52     
this angle and then one on the bottom so yeah I     
1:20:58     
I'll send them to you see what you think maybe I need to     
1:21:03     
um fix my my camera somehow just suggestions as how I can improve my 3D     
1:21:14     
microscope I'm getting some new a models this week     
1:21:19     
so yeah Mosaic of columns images one degree apart so it's like stacking them     
1:21:26     
together like that it's taking slices and putting them together well I'll I'll send you these     
1:21:33     
see what you think okay yeah that would be good um     
1:21:40     
yeah so any other comments or     
1:21:45     
questions um no I'm just working through the math for 10 cies     
1:21:54     
um it's an linear algebra and it's about     
1:22:00     
indeterminant math okay so noninvertible     
1:22:06     
um matrices uh because um the structure very     
1:22:13     
indeterminate okay they too depend on um initial     
1:22:20     
somewhat right yeah oh yeah yeah forend secrity that's pretty     
1:22:28     
important yeah well I can't I can't build them like I     
1:22:35     
would a bridge anyways right     
1:22:42     
yeah yeah yeah I think uh some of the gck people     
1:22:50     
or people interested in gck may have missed the beginning of the meeting where I went over the project and that     
1:22:56     
is actually available on neurostars which is neurostar.com     
1:23:06     
[Music]     
1:23:22     
you know write a proposal saying I'm going to do this thing that contributes to advancing this project so we have a     
1:23:29     
lot of things to do in that project but I would you know communicate with me uh     
1:23:34     
and you know before you write your proposal that would be the best way to do it and then we can talk about how     
1:23:41     
that fits into the longer term vision of the graph neural networks or daph     
1:23:47     
approach that we're doing uh dick said that uh     
1:23:53     
yes Susan nor would you cross an indeterminant Integrity Bridge     
1:24:02     
yeah cells work in this environment     
1:24:08     
yeah do you have any Susan do you have any ideas about like what the     
1:24:13     
differences between biological T secrity are and things like a bridge where you     
1:24:18     
would like mechanical T secrity I guess um well cells are are you could say     
1:24:25     
they're a spider web they're a more of a tensity dome than um than a tagr like     
1:24:35     
they're um they're held together with actin Rings all the way across the     
1:24:41     
surface and and um Tri Junctions and high Junctions and quad     
1:24:50     
Junctions Junctions just between the cells so     
1:24:55     
it's it's not a spider's web exactly but you know it's a it it it's based on hexagons but it's     
1:25:06     
hexagons are only the average of the type of shape you get     
1:25:12     
okay on Surface so it's a tiling but it's a fible tiling and it's it's stable     
1:25:20     
because it's it's heal at the edges like that sort of holds itself up     
1:25:28     
but it it's and then it's influenced by Bas though so it's also influenced by     
1:25:36     
its 3D structure so it's a surface structure but it's influenced by its     
1:25:42     
base how it's held so H try to get a     
1:25:49     
mathematical construct of that it's like really     
1:25:58     
yeah yeah that's something it certainly moves around yeah     
1:26:06     
yeah all right uh yeah so I think that's oh Morgan you want to say     
1:26:20     
something or you going to say something work     
1:26:28     
okay sorry yeah no no I hit the wrong button okay     
1:26:33     
just just heading out for school run all right all right so I guess that's it for     
1:26:40     
today uh thank you for attending and uh if you want to present anything to the     
1:26:45     
group we let me know we can do it um otherwise I keep in touch on email and     
1:26:51     
slack and all the places where we keep in touch and uh see you next     
1:26:56     
week
